{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Session4_6.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ckgpeace/EVA5B2/blob/main/S4/Session4_6.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ELOvT0LdZguR"
      },
      "source": [
        "### Importing the required libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0m2JWFliFfKT"
      },
      "source": [
        "# Importing the required libraries\n",
        "\n",
        "from __future__ import print_function\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "97P74b8-ZpKs"
      },
      "source": [
        "## Defining the model architecture\n",
        "\n",
        "\n",
        "1.   Sequential Block of Convolution layer has been used\n",
        "2. Only one layer of Maxpool is used\n",
        "3. BatchNorm, GAP and Drop out has been used. PLease check their position. You can play with their poistion to undertand the change in accuracy values\n",
        "4. Check for all the dimensions before and after Convolution layers\n",
        "5. Special attention on the last block - No RELU, No BactchNorm, No Dropout before prediction layer\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6H6o5OloDUgB"
      },
      "source": [
        "# Model 6:\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        \n",
        "        # Convolution Block1:\n",
        "        self.conv1 = nn.Sequential(\n",
        "        nn.Conv2d(1, 8, 3,  padding=1),\n",
        "        nn.ReLU(),\n",
        "        nn.BatchNorm2d(8),\n",
        "\n",
        "        nn.Conv2d(8, 8, 3,  padding=1),\n",
        "        nn.ReLU(),\n",
        "        nn.BatchNorm2d(8),\n",
        "\n",
        "        nn.Conv2d(8, 16, 3, padding=1),\n",
        "        nn.ReLU(),\n",
        "        nn.BatchNorm2d(16),\n",
        "        nn.MaxPool2d(2, 2),                 # Maxpool Layer\n",
        "        nn.Dropout(0.25)\n",
        "        ) # in = 28, out = 14, RF = 14\n",
        "\n",
        "        # Convolution Block2:   \n",
        "        self.conv2 = nn.Sequential(\n",
        "        nn.Conv2d(16, 16, 3),\n",
        "        nn.ReLU(),\n",
        "        nn.BatchNorm2d(16),\n",
        "\n",
        "        nn.Conv2d(16, 16, 3),\n",
        "        nn.ReLU(),\n",
        "        nn.BatchNorm2d(16),\n",
        "\n",
        "        nn.Conv2d(16, 16, 3),\n",
        "        nn.ReLU(),\n",
        "        nn.BatchNorm2d(16),\n",
        "        nn.Dropout(0.25)\n",
        "        ) # in = 14, out = 5, RF = 20\n",
        "\n",
        "        # Convolution Block3:\n",
        "        self.conv3 = nn.Sequential(\n",
        "        nn.Conv2d(16, 16, 3),\n",
        "        nn.ReLU(),\n",
        "        nn.BatchNorm2d(16),\n",
        "\n",
        "        nn.Conv2d(16, 32, 3),\n",
        "        nn.ReLU(),\n",
        "        nn.BatchNorm2d(32),\n",
        "\n",
        "        nn.Conv2d(32, 10, 1)\n",
        "        ) # in = 7, out = 4, RF = 26\n",
        "\n",
        "        # GAP layer\n",
        "        self.gap = nn.AvgPool2d(4) \n",
        "    \n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.conv3(x)\n",
        "        x = self.gap(x)\n",
        "        x = x.view(-1, 10)\n",
        "        return F.log_softmax(x)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OVa5OBnGbnCJ"
      },
      "source": [
        "## Model Summary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xdydjYTZFyi3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b23646c9-4c3f-41ae-bbb6-c62c000613cd"
      },
      "source": [
        "!pip install torchsummary\n",
        "from torchsummary import summary\n",
        "use_cuda = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "model = Net().to(device)\n",
        "summary(model, input_size=(1, 28, 28))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torchsummary in /usr/local/lib/python3.6/dist-packages (1.5.1)\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1            [-1, 8, 28, 28]              80\n",
            "              ReLU-2            [-1, 8, 28, 28]               0\n",
            "       BatchNorm2d-3            [-1, 8, 28, 28]              16\n",
            "            Conv2d-4            [-1, 8, 28, 28]             584\n",
            "              ReLU-5            [-1, 8, 28, 28]               0\n",
            "       BatchNorm2d-6            [-1, 8, 28, 28]              16\n",
            "            Conv2d-7           [-1, 16, 28, 28]           1,168\n",
            "              ReLU-8           [-1, 16, 28, 28]               0\n",
            "       BatchNorm2d-9           [-1, 16, 28, 28]              32\n",
            "        MaxPool2d-10           [-1, 16, 14, 14]               0\n",
            "          Dropout-11           [-1, 16, 14, 14]               0\n",
            "           Conv2d-12           [-1, 16, 12, 12]           2,320\n",
            "             ReLU-13           [-1, 16, 12, 12]               0\n",
            "      BatchNorm2d-14           [-1, 16, 12, 12]              32\n",
            "           Conv2d-15           [-1, 16, 10, 10]           2,320\n",
            "             ReLU-16           [-1, 16, 10, 10]               0\n",
            "      BatchNorm2d-17           [-1, 16, 10, 10]              32\n",
            "           Conv2d-18             [-1, 16, 8, 8]           2,320\n",
            "             ReLU-19             [-1, 16, 8, 8]               0\n",
            "      BatchNorm2d-20             [-1, 16, 8, 8]              32\n",
            "          Dropout-21             [-1, 16, 8, 8]               0\n",
            "           Conv2d-22             [-1, 16, 6, 6]           2,320\n",
            "             ReLU-23             [-1, 16, 6, 6]               0\n",
            "      BatchNorm2d-24             [-1, 16, 6, 6]              32\n",
            "           Conv2d-25             [-1, 32, 4, 4]           4,640\n",
            "             ReLU-26             [-1, 32, 4, 4]               0\n",
            "      BatchNorm2d-27             [-1, 32, 4, 4]              64\n",
            "           Conv2d-28             [-1, 10, 4, 4]             330\n",
            "        AvgPool2d-29             [-1, 10, 1, 1]               0\n",
            "================================================================\n",
            "Total params: 16,338\n",
            "Trainable params: 16,338\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 0.77\n",
            "Params size (MB): 0.06\n",
            "Estimated Total Size (MB): 0.83\n",
            "----------------------------------------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:63: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AnDsZgB3b34B"
      },
      "source": [
        "### Data loader - MNIST dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DqTWLaM5GHgH"
      },
      "source": [
        "torch.manual_seed(1)\n",
        "batch_size = 128\n",
        "\n",
        "kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    datasets.MNIST('../data', train=True, download=True,\n",
        "                    transform=transforms.Compose([\n",
        "                        transforms.ToTensor(),\n",
        "                        transforms.Normalize((0.1307,), (0.3081,))\n",
        "                    ])),\n",
        "    batch_size=batch_size, shuffle=True, **kwargs)\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    datasets.MNIST('../data', train=False, transform=transforms.Compose([\n",
        "                        transforms.ToTensor(),\n",
        "                        transforms.Normalize((0.1307,), (0.3081,))\n",
        "                    ])),\n",
        "    batch_size=batch_size, shuffle=True, **kwargs)\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9q5GALdRcFHm"
      },
      "source": [
        "### TRAIN and TEST functions to evaluate the model\n",
        "Negative Log Loss is used as loss function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8fDefDhaFlwH"
      },
      "source": [
        "from tqdm import tqdm\n",
        "def train(model, device, train_loader, optimizer, epoch):\n",
        "    model.train()\n",
        "    pbar = tqdm(train_loader)\n",
        "    for batch_idx, (data, target) in enumerate(pbar):\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = F.nll_loss(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        pbar.set_description(desc= f'loss={loss.item()} batch_id={batch_idx}')\n",
        "\n",
        "\n",
        "def test(model, device, test_loader):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model(data)\n",
        "            test_loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n",
        "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "\n",
        "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
        "        test_loss, correct, len(test_loader.dataset),\n",
        "        100. * correct / len(test_loader.dataset)))"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IOyWDWnlce_h"
      },
      "source": [
        "Finally!! Training the model and measuring loss and accuracy on test data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MMWbLWO6FuHb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6323bd85-56ac-4d73-dac7-ce1c6afed371"
      },
      "source": [
        "model = Net().to(device)\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
        "\n",
        "for epoch in range(1, 20):\n",
        "    train(model, device, train_loader, optimizer, epoch)\n",
        "    test(model, device, test_loader)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 0/469 [00:00<?, ?it/s]/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:63: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "loss=0.06360013037919998 batch_id=468: 100%|██████████| 469/469 [00:15<00:00, 31.00it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0592, Accuracy: 9831/10000 (98%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "loss=0.02867789752781391 batch_id=468: 100%|██████████| 469/469 [00:15<00:00, 30.51it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0371, Accuracy: 9889/10000 (99%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "loss=0.027006983757019043 batch_id=468: 100%|██████████| 469/469 [00:14<00:00, 32.03it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0283, Accuracy: 9911/10000 (99%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "loss=0.025313591584563255 batch_id=468: 100%|██████████| 469/469 [00:15<00:00, 29.33it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0257, Accuracy: 9920/10000 (99%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "loss=0.010297711007297039 batch_id=468: 100%|██████████| 469/469 [00:15<00:00, 30.24it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0227, Accuracy: 9927/10000 (99%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "loss=0.02375417947769165 batch_id=468: 100%|██████████| 469/469 [00:14<00:00, 32.10it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0207, Accuracy: 9935/10000 (99%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "loss=0.06187198683619499 batch_id=468: 100%|██████████| 469/469 [00:15<00:00, 30.58it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0212, Accuracy: 9934/10000 (99%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "loss=0.003474951721727848 batch_id=468: 100%|██████████| 469/469 [00:15<00:00, 30.46it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0210, Accuracy: 9921/10000 (99%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "loss=0.09437204152345657 batch_id=468: 100%|██████████| 469/469 [00:14<00:00, 31.73it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0159, Accuracy: 9946/10000 (99%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "loss=0.010342560708522797 batch_id=468: 100%|██████████| 469/469 [00:15<00:00, 30.48it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0169, Accuracy: 9948/10000 (99%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "loss=0.031973764300346375 batch_id=468: 100%|██████████| 469/469 [00:15<00:00, 31.27it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0195, Accuracy: 9933/10000 (99%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "loss=0.06317823380231857 batch_id=468: 100%|██████████| 469/469 [00:16<00:00, 29.31it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0186, Accuracy: 9943/10000 (99%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "loss=0.01414125319570303 batch_id=468: 100%|██████████| 469/469 [00:14<00:00, 31.32it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0165, Accuracy: 9945/10000 (99%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "loss=0.0018174051074311137 batch_id=468: 100%|██████████| 469/469 [00:15<00:00, 30.08it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0166, Accuracy: 9943/10000 (99%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "loss=0.003661229507997632 batch_id=468: 100%|██████████| 469/469 [00:15<00:00, 29.47it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0191, Accuracy: 9943/10000 (99%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "loss=0.002132546389475465 batch_id=468: 100%|██████████| 469/469 [00:14<00:00, 31.96it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0153, Accuracy: 9949/10000 (99%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "loss=0.005010238382965326 batch_id=468: 100%|██████████| 469/469 [00:15<00:00, 29.74it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0187, Accuracy: 9940/10000 (99%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "loss=0.004511484410613775 batch_id=468: 100%|██████████| 469/469 [00:15<00:00, 30.02it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0162, Accuracy: 9950/10000 (100%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "loss=0.005666978191584349 batch_id=468: 100%|██████████| 469/469 [00:15<00:00, 30.76it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0172, Accuracy: 9950/10000 (100%)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}